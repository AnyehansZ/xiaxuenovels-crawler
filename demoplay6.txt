import asyncio
import random
from playwright.async_api import async_playwright

# This limits us to 3 concurrent tabs so we don't overwhelm the server
sem = asyncio.Semaphore(3)

async def polite_scrape(browser, url):
    async with sem: # The 'gatekeeper' only lets 3 through at a time
        context = await browser.new_context()
        page = await context.new_page()
        
        # Add a random 'human' delay before the request
        await asyncio.sleep(random.uniform(1, 3))
        
        print(f"ðŸ“¡ Requesting: {url}")
        await page.goto(url)
        
        title = await page.title()
        await context.close()
        return title

async def main():
    urls = [f"https://quotes.toscrape.com/page/{i}/" for i in range(1, 7)]
    
    async with async_playwright() as p:
        browser = await p.chromium.launch()
        tasks = [polite_scrape(browser, url) for url in urls]
        await asyncio.gather(*tasks)
        await browser.close()

if __name__ == "__main__":
    asyncio.run(main())